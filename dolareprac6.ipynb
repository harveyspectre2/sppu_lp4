{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc841248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from imageio import imread\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import tf_slim as slim\n",
    "from tf_slim.nets import inception\n",
    "import tf_slim as slim\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4351718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-slim in c:\\users\\rohan\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in c:\\users\\rohan\\anaconda3\\lib\\site-packages (from tf-slim) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tf-slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10d69945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\rohan\\anaconda3\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\rohan\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "445aa18d",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'https://www.kaggle.com/code/imsparsh/large-categories-image-classifier-inception-v3/input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m predict_output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     11\u001b[0m class_names_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.kaggle.com/code/imsparsh/large-categories-image-classifier-inception-v3/input\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(class_names_path) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     13\u001b[0m     class_names \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'https://www.kaggle.com/code/imsparsh/large-categories-image-classifier-inception-v3/input'"
     ]
    }
   ],
   "source": [
    "#Data Loading\n",
    "#etup all initial variables with default file locations and respective values.\n",
    "ckpt_path = \"/kaggle/input/inception_v3.ckpt\"\n",
    "images_path = \"/kaggle/input/animals/*\"\n",
    "img_width=299\n",
    "img_height = 299\n",
    "batch_size = 16\n",
    "batch_shape = [batch_size, img_height, img_width, 3]\n",
    "num_classes = 1001\n",
    "predict_output = []\n",
    "class_names_path = \"https://www.kaggle.com/code/imsparsh/large-categories-image-classifier-inception-v3/input\"\n",
    "with open(class_names_path) as f:\n",
    "    class_names = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45c7b252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1697: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.legacy_tf_layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mplaceholder(tf\u001b[38;5;241m.\u001b[39mfloat32, shape\u001b[38;5;241m=\u001b[39mbatch_shape)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m slim\u001b[38;5;241m.\u001b[39marg_scope(inception\u001b[38;5;241m.\u001b[39minception_v3_arg_scope()):\n\u001b[1;32m----> 4\u001b[0m     logits, end_points \u001b[38;5;241m=\u001b[39m inception\u001b[38;5;241m.\u001b[39minception_v3(\n\u001b[0;32m      5\u001b[0m         X, num_classes\u001b[38;5;241m=\u001b[39mnum_classes, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     )\n\u001b[0;32m      8\u001b[0m predictions \u001b[38;5;241m=\u001b[39m end_points[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      9\u001b[0m saver \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mSaver(slim\u001b[38;5;241m.\u001b[39mget_model_variables())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tf_slim\\nets\\inception_v3.py:583\u001b[0m, in \u001b[0;36minception_v3\u001b[1;34m(inputs, num_classes, is_training, dropout_keep_prob, min_depth, depth_multiplier, prediction_fn, spatial_squeeze, reuse, create_aux_logits, scope)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m variable_scope\u001b[38;5;241m.\u001b[39mvariable_scope(\n\u001b[0;32m    580\u001b[0m     scope, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInceptionV3\u001b[39m\u001b[38;5;124m'\u001b[39m, [inputs, num_classes], reuse\u001b[38;5;241m=\u001b[39mreuse) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[0;32m    581\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m arg_scope(\n\u001b[0;32m    582\u001b[0m       [layers_lib\u001b[38;5;241m.\u001b[39mbatch_norm, layers_lib\u001b[38;5;241m.\u001b[39mdropout], is_training\u001b[38;5;241m=\u001b[39mis_training):\n\u001b[1;32m--> 583\u001b[0m     net, end_points \u001b[38;5;241m=\u001b[39m inception_v3_base(\n\u001b[0;32m    584\u001b[0m         inputs,\n\u001b[0;32m    585\u001b[0m         scope\u001b[38;5;241m=\u001b[39mscope,\n\u001b[0;32m    586\u001b[0m         min_depth\u001b[38;5;241m=\u001b[39mmin_depth,\n\u001b[0;32m    587\u001b[0m         depth_multiplier\u001b[38;5;241m=\u001b[39mdepth_multiplier)\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;66;03m# Auxiliary Head logits\u001b[39;00m\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m create_aux_logits \u001b[38;5;129;01mand\u001b[39;00m num_classes:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tf_slim\\nets\\inception_v3.py:117\u001b[0m, in \u001b[0;36minception_v3_base\u001b[1;34m(inputs, final_endpoint, min_depth, depth_multiplier, scope)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m arg_scope(\n\u001b[0;32m    112\u001b[0m     [layers\u001b[38;5;241m.\u001b[39mconv2d, layers_lib\u001b[38;5;241m.\u001b[39mmax_pool2d, layers_lib\u001b[38;5;241m.\u001b[39mavg_pool2d],\n\u001b[0;32m    113\u001b[0m     stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    114\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVALID\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    115\u001b[0m   \u001b[38;5;66;03m# 299 x 299 x 3\u001b[39;00m\n\u001b[0;32m    116\u001b[0m   end_point \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConv2d_1a_3x3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 117\u001b[0m   net \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mconv2d(inputs, depth(\u001b[38;5;241m32\u001b[39m), [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m], stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, scope\u001b[38;5;241m=\u001b[39mend_point)\n\u001b[0;32m    118\u001b[0m   end_points[end_point] \u001b[38;5;241m=\u001b[39m net\n\u001b[0;32m    119\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m end_point \u001b[38;5;241m==\u001b[39m final_endpoint:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tf_slim\\ops\\arg_scope.py:184\u001b[0m, in \u001b[0;36madd_arg_scope.<locals>.func_with_args\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m   current_args \u001b[38;5;241m=\u001b[39m current_scope[key_func]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    183\u001b[0m   current_args\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m--> 184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcurrent_args)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tf_slim\\layers\\layers.py:1171\u001b[0m, in \u001b[0;36mconvolution2d\u001b[1;34m(inputs, num_outputs, kernel_size, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[38;5;129m@add_arg_scope\u001b[39m\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvolution2d\u001b[39m(inputs,\n\u001b[0;32m   1153\u001b[0m                   num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1169\u001b[0m                   trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1170\u001b[0m                   scope\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1171\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m convolution(\n\u001b[0;32m   1172\u001b[0m       inputs,\n\u001b[0;32m   1173\u001b[0m       num_outputs,\n\u001b[0;32m   1174\u001b[0m       kernel_size,\n\u001b[0;32m   1175\u001b[0m       stride,\n\u001b[0;32m   1176\u001b[0m       padding,\n\u001b[0;32m   1177\u001b[0m       data_format,\n\u001b[0;32m   1178\u001b[0m       rate,\n\u001b[0;32m   1179\u001b[0m       activation_fn,\n\u001b[0;32m   1180\u001b[0m       normalizer_fn,\n\u001b[0;32m   1181\u001b[0m       normalizer_params,\n\u001b[0;32m   1182\u001b[0m       weights_initializer,\n\u001b[0;32m   1183\u001b[0m       weights_regularizer,\n\u001b[0;32m   1184\u001b[0m       biases_initializer,\n\u001b[0;32m   1185\u001b[0m       biases_regularizer,\n\u001b[0;32m   1186\u001b[0m       reuse,\n\u001b[0;32m   1187\u001b[0m       variables_collections,\n\u001b[0;32m   1188\u001b[0m       outputs_collections,\n\u001b[0;32m   1189\u001b[0m       trainable,\n\u001b[0;32m   1190\u001b[0m       scope,\n\u001b[0;32m   1191\u001b[0m       conv_dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tf_slim\\ops\\arg_scope.py:184\u001b[0m, in \u001b[0;36madd_arg_scope.<locals>.func_with_args\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m   current_args \u001b[38;5;241m=\u001b[39m current_scope[key_func]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    183\u001b[0m   current_args\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m--> 184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcurrent_args)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tf_slim\\layers\\layers.py:1098\u001b[0m, in \u001b[0;36mconvolution\u001b[1;34m(inputs, num_outputs, kernel_size, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope, conv_dims)\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalizer_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m   normalizer_params \u001b[38;5;241m=\u001b[39m normalizer_params \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m-> 1098\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m normalizer_fn(outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnormalizer_params)\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m activation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m activation_fn(outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tf_slim\\ops\\arg_scope.py:184\u001b[0m, in \u001b[0;36madd_arg_scope.<locals>.func_with_args\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m   current_args \u001b[38;5;241m=\u001b[39m current_scope[key_func]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    183\u001b[0m   current_args\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m--> 184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcurrent_args)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tf_slim\\layers\\layers.py:663\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(inputs, decay, center, scale, epsilon, activation_fn, param_initializers, param_regularizers, updates_collections, is_training, reuse, variables_collections, outputs_collections, trainable, batch_weights, fused, data_format, zero_debias_moving_mean, scope, renorm, renorm_clipping, renorm_decay, adjustment)\u001b[0m\n\u001b[0;32m    661\u001b[0m beta_regularizer \u001b[38;5;241m=\u001b[39m param_regularizers\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    662\u001b[0m gamma_regularizer \u001b[38;5;241m=\u001b[39m param_regularizers\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 663\u001b[0m layer \u001b[38;5;241m=\u001b[39m normalization_layers\u001b[38;5;241m.\u001b[39mBatchNormalization(\n\u001b[0;32m    664\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    665\u001b[0m     momentum\u001b[38;5;241m=\u001b[39mdecay,\n\u001b[0;32m    666\u001b[0m     epsilon\u001b[38;5;241m=\u001b[39mepsilon,\n\u001b[0;32m    667\u001b[0m     center\u001b[38;5;241m=\u001b[39mcenter,\n\u001b[0;32m    668\u001b[0m     scale\u001b[38;5;241m=\u001b[39mscale,\n\u001b[0;32m    669\u001b[0m     beta_initializer\u001b[38;5;241m=\u001b[39mbeta_initializer,\n\u001b[0;32m    670\u001b[0m     gamma_initializer\u001b[38;5;241m=\u001b[39mgamma_initializer,\n\u001b[0;32m    671\u001b[0m     moving_mean_initializer\u001b[38;5;241m=\u001b[39mmoving_mean_initializer,\n\u001b[0;32m    672\u001b[0m     moving_variance_initializer\u001b[38;5;241m=\u001b[39mmoving_variance_initializer,\n\u001b[0;32m    673\u001b[0m     beta_regularizer\u001b[38;5;241m=\u001b[39mbeta_regularizer,\n\u001b[0;32m    674\u001b[0m     gamma_regularizer\u001b[38;5;241m=\u001b[39mgamma_regularizer,\n\u001b[0;32m    675\u001b[0m     trainable\u001b[38;5;241m=\u001b[39mtrainable,\n\u001b[0;32m    676\u001b[0m     renorm\u001b[38;5;241m=\u001b[39mrenorm,\n\u001b[0;32m    677\u001b[0m     renorm_clipping\u001b[38;5;241m=\u001b[39mrenorm_clipping,\n\u001b[0;32m    678\u001b[0m     renorm_momentum\u001b[38;5;241m=\u001b[39mrenorm_decay,\n\u001b[0;32m    679\u001b[0m     adjustment\u001b[38;5;241m=\u001b[39madjustment,\n\u001b[0;32m    680\u001b[0m     name\u001b[38;5;241m=\u001b[39msc\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    681\u001b[0m     _scope\u001b[38;5;241m=\u001b[39msc,\n\u001b[0;32m    682\u001b[0m     _reuse\u001b[38;5;241m=\u001b[39mreuse,\n\u001b[0;32m    683\u001b[0m     fused\u001b[38;5;241m=\u001b[39mfused)\n\u001b[0;32m    684\u001b[0m outputs \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mapply(inputs, training\u001b[38;5;241m=\u001b[39mis_training)\n\u001b[0;32m    686\u001b[0m \u001b[38;5;66;03m# Add variables to collections.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\layers\\normalization.py:30\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[0;32m     29\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatchNormalization\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatchNorm\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m normalization\u001b[38;5;241m.\u001b[39mBatchNormalization\n\u001b[0;32m     31\u001b[0m   \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_normalization\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_norm\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m normalization\u001b[38;5;241m.\u001b[39mbatch_normalization\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:66\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m---> 66\u001b[0m   module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load()\n\u001b[0;32m     67\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, item)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:49\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_module_globals[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1126\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.legacy_tf_layers'"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "\n",
    "with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "    logits, end_points = inception.inception_v3(\n",
    "        X, num_classes=num_classes, is_training=False\n",
    "    )\n",
    "\n",
    "predictions = end_points[\"Predictions\"]\n",
    "saver = tf.train.Saver(slim.get_model_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe465683",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3774859268.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Load Pre-Trained Model\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Load Pre-Trained Model\n",
    "session_creator = tf.train.ChiefSessionCreator(\n",
    "        scaffold=tf.train.Scaffold(saver=saver),\n",
    "        checkpoint_filename_with_path=ckpt_path,\n",
    "        master='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9754aa07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
